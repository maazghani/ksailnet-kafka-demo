{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating Kafka Resiliency with Pod Topology Constraints in Kubernetes\n",
    "----------\n",
    "\n",
    "If you would like to run this notebook live, you can create a codespace using the devcontainer in this repository. The devcontainer has all the necessary tools and dependencies installed. Once launched, you can open this notebook, click Clear All Outputs and run the cells. \n",
    "\n",
    "## Introduction\n",
    "In this notebook, we will simulate a Kafka cluster with 3 brokers in a k3s environment. We will use Pod Topology Constraints to ensure that the Kafka brokers and Zookeeper nodes are scheduled on different nodes. We will then simulate a node failure and observe how the Kafka cluster behaves.\n",
    "\n",
    "## Step 1: Create a k3s cluster\n",
    "Note: We will label the k3s nodes with topology.kubernetes.io/zone so that we can use Pod Topology Constraints to ensure that the Kafka brokers and Zookeeper nodes are scheduled on different nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mINFO\u001b[0m[0000] Prep: Network                                \n",
      "\u001b[36mINFO\u001b[0m[0000] Created network 'k3d-kube-cluster'           \n",
      "\u001b[36mINFO\u001b[0m[0000] Created image volume k3d-kube-cluster-images \n",
      "\u001b[36mINFO\u001b[0m[0000] Starting new tools node...                   \n",
      "\u001b[36mINFO\u001b[0m[0000] Pulling image 'ghcr.io/k3d-io/k3d-tools:5.6.0' \n",
      "\u001b[36mINFO\u001b[0m[0001] Creating node 'k3d-kube-cluster-server-0'    \n",
      "\u001b[36mINFO\u001b[0m[0002] Pulling image 'docker.io/rancher/k3s:v1.27.4-k3s1' \n",
      "\u001b[36mINFO\u001b[0m[0002] Starting Node 'k3d-kube-cluster-tools'       \n",
      "\u001b[36mINFO\u001b[0m[0005] Creating node 'k3d-kube-cluster-agent-0'     \n",
      "\u001b[36mINFO\u001b[0m[0006] Creating node 'k3d-kube-cluster-agent-1'     \n",
      "\u001b[36mINFO\u001b[0m[0006] Creating node 'k3d-kube-cluster-agent-2'     \n",
      "\u001b[36mINFO\u001b[0m[0006] Creating LoadBalancer 'k3d-kube-cluster-serverlb' \n",
      "\u001b[36mINFO\u001b[0m[0007] Pulling image 'ghcr.io/k3d-io/k3d-proxy:5.6.0' \n",
      "\u001b[36mINFO\u001b[0m[0010] Using the k3d-tools node to gather environment information \n",
      "\u001b[36mINFO\u001b[0m[0010] HostIP: using network gateway 172.18.0.1 address \n",
      "\u001b[36mINFO\u001b[0m[0010] Starting cluster 'kube-cluster'              \n",
      "\u001b[36mINFO\u001b[0m[0010] Starting servers...                          \n",
      "\u001b[36mINFO\u001b[0m[0011] Starting Node 'k3d-kube-cluster-server-0'    \n",
      "\u001b[36mINFO\u001b[0m[0014] Starting agents...                           \n",
      "\u001b[36mINFO\u001b[0m[0014] Starting Node 'k3d-kube-cluster-agent-1'     \n",
      "\u001b[36mINFO\u001b[0m[0014] Starting Node 'k3d-kube-cluster-agent-2'     \n",
      "\u001b[36mINFO\u001b[0m[0014] Starting Node 'k3d-kube-cluster-agent-0'     \n",
      "\u001b[36mINFO\u001b[0m[0020] Starting helpers...                          \n",
      "\u001b[36mINFO\u001b[0m[0020] Starting Node 'k3d-kube-cluster-serverlb'    \n",
      "\u001b[36mINFO\u001b[0m[0026] Injecting records for hostAliases (incl. host.k3d.internal) and for 5 network members into CoreDNS configmap... \n",
      "\u001b[36mINFO\u001b[0m[0028] Cluster 'kube-cluster' created successfully! \n",
      "\u001b[36mINFO\u001b[0m[0028] You can now use it like this:                \n",
      "kubectl cluster-info\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/bin/k3d cluster create kube-cluster \\\n",
    "  --agents 3 \\\n",
    "  --k3s-node-label topology.kubernetes.io/zone=zone-a@agent:0 \\\n",
    "  --k3s-node-label topology.kubernetes.io/zone=zone-b@agent:1 \\\n",
    "  --k3s-node-label topology.kubernetes.io/zone=zone-c@agent:2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Deploy Kafka\n",
    "The following stateful set can be found under deploy/kafka/01-sts.yaml. It deploys a Kafka cluster with 3 brokers. The stateful set uses Pod Topology Constraints to ensure that the Kafka brokers are scheduled on different nodes.\n",
    "\n",
    "We will also deploy a headless service for the Kafka brokers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "serviceaccount/kafka unchanged\n",
      "service/kafka-headless unchanged\n",
      "statefulset.apps/kafka created\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f deploy/kafka/01-sts.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that each pod is running on a different node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME      READY   STATUS    RESTARTS   AGE     IP          NODE                       NOMINATED NODE   READINESS GATES\n",
      "kafka-0   1/1     Running   0          3m37s   10.42.0.4   k3d-kube-cluster-agent-0   <none>           <none>\n",
      "kafka-1   1/1     Running   0          3m37s   10.42.2.5   k3d-kube-cluster-agent-2   <none>           <none>\n",
      "kafka-2   1/1     Running   0          3m37s   10.42.1.4   k3d-kube-cluster-agent-1   <none>           <none>\n"
     ]
    }
   ],
   "source": [
    "! kubectl get pods -n kafka -o wide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the stateful set and headless service deployed, we can now test the Kafka cluster.\n",
    "We will exec into one of the Kafka brokers and create a topic called \"test\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0304 13:12:47.974390   29512 log.go:245] (0xc0000da0b0) (0xc00056dcc0) Create stream\n",
      "I0304 13:12:47.974467   29512 log.go:245] (0xc0000da0b0) (0xc00056dcc0) Stream added, broadcasting: 1\n",
      "I0304 13:12:47.975648   29512 log.go:245] (0xc0000da0b0) Reply frame received for 1\n",
      "I0304 13:12:47.975670   29512 log.go:245] (0xc0000da0b0) (0xc00053a6e0) Create stream\n",
      "I0304 13:12:47.975678   29512 log.go:245] (0xc0000da0b0) (0xc00053a6e0) Stream added, broadcasting: 3\n",
      "I0304 13:12:47.976528   29512 log.go:245] (0xc0000da0b0) Reply frame received for 3\n",
      "I0304 13:12:47.976549   29512 log.go:245] (0xc0000da0b0) (0xc0005ea000) Create stream\n",
      "I0304 13:12:47.976559   29512 log.go:245] (0xc0000da0b0) (0xc0005ea000) Stream added, broadcasting: 5\n",
      "I0304 13:12:47.977393   29512 log.go:245] (0xc0000da0b0) Reply frame received for 5\n",
      "I0304 13:12:47.977409   29512 log.go:245] (0xc0000da0b0) (0xc0008a8000) Create stream\n",
      "I0304 13:12:47.977418   29512 log.go:245] (0xc0000da0b0) (0xc0008a8000) Stream added, broadcasting: 7\n",
      "I0304 13:12:47.978242   29512 log.go:245] (0xc0000da0b0) Reply frame received for 7\n",
      "I0304 13:12:47.978334   29512 log.go:245] (0xc0008a8000) (7) Writing data frame\n",
      "I0304 13:12:50.106386   29512 log.go:245] (0xc0000da0b0) Data frame received for 5\n",
      "I0304 13:12:50.106410   29512 log.go:245] (0xc0005ea000) (5) Data frame handling\n",
      "I0304 13:12:50.106442   29512 log.go:245] (0xc0005ea000) (5) Data frame sent\n",
      "Created topic test.\n",
      "I0304 13:12:50.463566   29512 log.go:245] (0xc0000da0b0) Data frame received for 5\n",
      "I0304 13:12:50.463583   29512 log.go:245] (0xc0005ea000) (5) Data frame handling\n",
      "I0304 13:12:50.465110   29512 log.go:245] (0xc0000da0b0) Data frame received for 1\n",
      "I0304 13:12:50.465136   29512 log.go:245] (0xc0000da0b0) (0xc0008a8000) Stream removed, broadcasting: 7\n",
      "I0304 13:12:50.465168   29512 log.go:245] (0xc00056dcc0) (1) Data frame handling\n",
      "I0304 13:12:50.465198   29512 log.go:245] (0xc00056dcc0) (1) Data frame sent\n",
      "I0304 13:12:50.465211   29512 log.go:245] (0xc0000da0b0) (0xc00056dcc0) Stream removed, broadcasting: 1\n",
      "I0304 13:12:50.465227   29512 log.go:245] (0xc0000da0b0) (0xc00053a6e0) Stream removed, broadcasting: 3\n",
      "I0304 13:12:50.465242   29512 log.go:245] (0xc0000da0b0) (0xc00053a6e0) Stream removed, broadcasting: 3\n",
      "I0304 13:12:50.465296   29512 log.go:245] (0xc0000da0b0) Go away received\n",
      "I0304 13:12:50.465454   29512 log.go:245] (0xc0000da0b0) (0xc00056dcc0) Stream removed, broadcasting: 1\n",
      "I0304 13:12:50.465470   29512 log.go:245] (0xc0000da0b0) (0xc00053a6e0) Stream removed, broadcasting: 3\n",
      "I0304 13:12:50.465480   29512 log.go:245] (0xc0000da0b0) (0xc0005ea000) Stream removed, broadcasting: 5\n",
      "I0304 13:12:50.465490   29512 log.go:245] (0xc0000da0b0) (0xc0008a8000) Stream removed, broadcasting: 7\n"
     ]
    }
   ],
   "source": [
    "! kubectl -n kafka exec -it kafka-0 -- kafka-topics --create --topic test --partitions 3 --replication-factor 3 --bootstrap-server kafka-0.kafka-headless.kafka.svc.cluster.local:9092"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the topic created, if we run a describe topic command, we should see the topic \"test\" with 3 partitions and a replication factor of 3.\n",
    "\n",
    "```\n",
    "Topic: test     TopicId: WmMXgsr2RcyZU9ohfoTUWQ PartitionCount: 3       ReplicationFactor: 3    Configs: \n",
    "        Topic: test     Partition: 0    Leader: 0       Replicas: 0,1,2 Isr: 0,1,2\n",
    "        Topic: test     Partition: 1    Leader: 1       Replicas: 1,2,0 Isr: 1,2,0\n",
    "        Topic: test     Partition: 2    Leader: 2       Replicas: 2,0,1 Isr: 2,0,1\n",
    "The output above and below shows there are 3 in-sync replicas.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0304 13:12:58.736532   29826 log.go:245] (0xc0000da4d0) (0xc0002405a0) Create stream\n",
      "I0304 13:12:58.736633   29826 log.go:245] (0xc0000da4d0) (0xc0002405a0) Stream added, broadcasting: 1\n",
      "I0304 13:12:58.738461   29826 log.go:245] (0xc0000da4d0) Reply frame received for 1\n",
      "I0304 13:12:58.738494   29826 log.go:245] (0xc0000da4d0) (0xc000394d20) Create stream\n",
      "I0304 13:12:58.738506   29826 log.go:245] (0xc0000da4d0) (0xc000394d20) Stream added, broadcasting: 3\n",
      "I0304 13:12:58.739552   29826 log.go:245] (0xc0000da4d0) Reply frame received for 3\n",
      "I0304 13:12:58.739585   29826 log.go:245] (0xc0000da4d0) (0xc00034db80) Create stream\n",
      "I0304 13:12:58.739599   29826 log.go:245] (0xc0000da4d0) (0xc00034db80) Stream added, broadcasting: 5\n",
      "I0304 13:12:58.741812   29826 log.go:245] (0xc0000da4d0) Reply frame received for 5\n",
      "I0304 13:12:58.741835   29826 log.go:245] (0xc0000da4d0) (0xc000240640) Create stream\n",
      "I0304 13:12:58.741847   29826 log.go:245] (0xc0000da4d0) (0xc000240640) Stream added, broadcasting: 7\n",
      "I0304 13:12:58.743923   29826 log.go:245] (0xc0000da4d0) Reply frame received for 7\n",
      "I0304 13:12:58.744090   29826 log.go:245] (0xc000240640) (7) Writing data frame\n",
      "I0304 13:13:02.741345   29826 log.go:245] (0xc0000da4d0) Data frame received for 5\n",
      "I0304 13:13:02.741374   29826 log.go:245] (0xc00034db80) (5) Data frame handling\n",
      "I0304 13:13:02.741396   29826 log.go:245] (0xc00034db80) (5) Data frame sent\n",
      "Topic: testI0304 13:13:02.741608   29826 log.go:245] (0xc0000da4d0) Data frame received for 5\n",
      "I0304 13:13:02.741637   29826 log.go:245] (0xc00034db80) (5) Data frame handling\n",
      "I0304 13:13:02.741657   29826 log.go:245] (0xc00034db80) (5) Data frame sent\n",
      "\tTopicId: IreMqXQkSMuSsmp6G5FL4A\tPartitionCount: 3\tReplicationFactor: 3\tConfigs: \n",
      "I0304 13:13:02.743025   29826 log.go:245] (0xc0000da4d0) Data frame received for 5\n",
      "I0304 13:13:02.743059   29826 log.go:245] (0xc00034db80) (5) Data frame handling\n",
      "I0304 13:13:02.743081   29826 log.go:245] (0xc00034db80) (5) Data frame sent\n",
      "I0304 13:13:02.743095   29826 log.go:245] (0xc0000da4d0) Data frame received for 5\n",
      "I0304 13:13:02.743106   29826 log.go:245] (0xc00034db80) (5) Data frame handling\n",
      "\tTopic: test\tPartition: 0\tLeader: 1I0304 13:13:02.743128   29826 log.go:245] (0xc00034db80) (5) Data frame sent\n",
      "I0304 13:13:02.743629   29826 log.go:245] (0xc0000da4d0) Data frame received for 5\n",
      "I0304 13:13:02.743670   29826 log.go:245] (0xc00034db80) (5) Data frame handling\n",
      "I0304 13:13:02.743698   29826 log.go:245] (0xc00034db80) (5) Data frame sent\n",
      "\tReplicas: 1,2,0I0304 13:13:02.743963   29826 log.go:245] (0xc0000da4d0) Data frame received for 5\n",
      "I0304 13:13:02.743982   29826 log.go:245] (0xc00034db80) (5) Data frame handling\n",
      "I0304 13:13:02.744000   29826 log.go:245] (0xc00034db80) (5) Data frame sent\n",
      "I0304 13:13:02.744011   29826 log.go:245] (0xc0000da4d0) Data frame received for 5\n",
      "\tIsr: 1,2,0I0304 13:13:02.744022   29826 log.go:245] (0xc00034db80) (5) Data frame handling\n",
      "I0304 13:13:02.744048   29826 log.go:245] (0xc00034db80) (5) Data frame sent\n",
      "\n",
      "I0304 13:13:02.745420   29826 log.go:245] (0xc0000da4d0) Data frame received for 5\n",
      "I0304 13:13:02.745434   29826 log.go:245] (0xc00034db80) (5) Data frame handling\n",
      "I0304 13:13:02.745442   29826 log.go:245] (0xc00034db80) (5) Data frame sent\n",
      "I0304 13:13:02.745450   29826 log.go:245] (0xc0000da4d0) Data frame received for 5\n",
      "I0304 13:13:02.745456   29826 log.go:245] (0xc00034db80) (5) Data frame handling\n",
      "\tTopic: test\tPartition: 1\tLeader: 2\tReplicas: 2,0,1\tIsr: 2,0,1\n",
      "\tTopic: test\tPartition: 2\tLeader: 0\tReplicas: 0,1,2\tIsr: 0,1,2\n",
      "I0304 13:13:02.745518   29826 log.go:245] (0xc00034db80) (5) Data frame sent\n",
      "I0304 13:13:03.154650   29826 log.go:245] (0xc0000da4d0) Data frame received for 5\n",
      "I0304 13:13:03.154675   29826 log.go:245] (0xc00034db80) (5) Data frame handling\n",
      "I0304 13:13:03.156239   29826 log.go:245] (0xc0000da4d0) (0xc000394d20) Stream removed, broadcasting: 3\n",
      "I0304 13:13:03.156287   29826 log.go:245] (0xc0000da4d0) Data frame received for 1\n",
      "I0304 13:13:03.156315   29826 log.go:245] (0xc0000da4d0) (0xc000394d20) Stream removed, broadcasting: 3\n",
      "I0304 13:13:03.156345   29826 log.go:245] (0xc0002405a0) (1) Data frame handling\n",
      "I0304 13:13:03.156362   29826 log.go:245] (0xc0002405a0) (1) Data frame sent\n",
      "I0304 13:13:03.156387   29826 log.go:245] (0xc0000da4d0) (0xc0002405a0) Stream removed, broadcasting: 1\n",
      "I0304 13:13:03.156420   29826 log.go:245] (0xc0000da4d0) (0xc000240640) Stream removed, broadcasting: 7\n",
      "I0304 13:13:03.156468   29826 log.go:245] (0xc0000da4d0) Go away received\n",
      "I0304 13:13:03.156589   29826 log.go:245] (0xc0000da4d0) (0xc0002405a0) Stream removed, broadcasting: 1\n",
      "I0304 13:13:03.156609   29826 log.go:245] (0xc0000da4d0) (0xc000394d20) Stream removed, broadcasting: 3\n",
      "I0304 13:13:03.156618   29826 log.go:245] (0xc0000da4d0) (0xc00034db80) Stream removed, broadcasting: 5\n",
      "I0304 13:13:03.156630   29826 log.go:245] (0xc0000da4d0) (0xc000240640) Stream removed, broadcasting: 7\n"
     ]
    }
   ],
   "source": [
    "! kubectl -n kafka exec -it kafka-0 -- kafka-topics --describe --topic test --bootstrap-server kafka-0.kafka-headless.kafka.svc.cluster.local:9092"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Simulate a node failure\n",
    "We will simulate a node failure by scaling the stateful set down to 2 replicas. We will then describe the topic again and observe the change in the number of in-sync replicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! kubectl -n kafka scale sts kafka --replicas=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! kubectl -n kafka exec -it kafka-0 -- kafka-topics --describe --topic test --bootstrap-server kafka-0.kafka-headless.kafka.svc.cluster.local:9092"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
